{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32c02243",
      "metadata": {},
      "source": [
        "# Run tools and rasterizers \n",
        "\n",
        "This notebook shows how to:\n",
        "\n",
        "1) **Run a tool** (e.g., `HoverNetTool`) to produce instance outputs (`.dat`).\n",
        "2) **Rasterize** those instance outputs to pixel‑aligned feature tensors via `HoverNetRasterizer`.\n",
        "3) **Inspect / visualize** a few channels to sanity‑check the pipeline.\n",
        "\n",
        "> The classes used here come from your repo modules:\n",
        ">\n",
        ">- `tools.py`: `Tool`, `HoverNetTool`\n",
        ">- `rasterizers.py`: `Rasterizer`, `HoverNetRasterizer` + common rasterization functions\n",
        "\n",
        "**Requirements** (install in your environment):\n",
        "- `tiatoolbox` (for HoVer‑Net)\n",
        "- `torch`, `numpy`, `Pillow`, `joblib`, `tqdm`, `scikit-image`, `scipy`\n",
        "\n",
        "You can adapt this notebook to other tools by swapping out the `Tool`/`Rasterizer` classes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc754c8d",
      "metadata": {},
      "source": [
        "## Point this notebook to your repo\n",
        "Set `REPO_ROOT` to the folder containing `tools.py` and `rasterizers.py`. If you're running from inside the repo, you can leave it as `'.'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648b02c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_ROOT = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
        "sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "from tbm.tools import HoverNetTool\n",
        "from tbm.rasterizers import HoverNetRasterizer\n",
        "\n",
        "import os, torch\n",
        "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dad0fa7",
      "metadata": {},
      "source": [
        "## 1) Imports and configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea26e476",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Where your input images live (TIFF/PNG/JPG). These can be tiles or small patches.\n",
        "#IMAGE_DIR = Path('sample_images')  # <-- replace with your dataset folder\n",
        "IMAGE_DIR = (REPO_ROOT / \"sample_images\").resolve()\n",
        "IMAGE_EXTS = ('.tif', '.tiff', '.png', '.jpg', '.jpeg')\n",
        "\n",
        "# Where to write tool outputs (.dat) and rasterized features (.pt)\n",
        "OUT_DIR = Path('outputs')\n",
        "TOOL_OUT_DIR = OUT_DIR / 'tool_outputs'\n",
        "FEAT_OUT_DIR = OUT_DIR / 'features'\n",
        "TOOL_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "FEAT_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Device for HoVerNet. Change to 'cpu' if you don't have a GPU.\n",
        "DEVICE = 'cpu'  # or 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ca2628",
      "metadata": {},
      "source": [
        "## Collect a small list of images\n",
        "We recommend starting with a handful of images to validate the pipeline end‑to‑end. You can scale up later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020b99dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_images(folder: Path, exts=IMAGE_EXTS, limit=None):\n",
        "    paths = [p for p in folder.rglob('*') if p.suffix.lower() in exts]\n",
        "    paths.sort()\n",
        "    if limit is not None:\n",
        "        paths = paths[:limit]\n",
        "    return paths\n",
        "\n",
        "# LIMIT is optional; set to None to process everything found\n",
        "LIMIT = 4\n",
        "image_paths = list_images(IMAGE_DIR, limit=LIMIT)\n",
        "print(f'Found {len(image_paths)} images:')\n",
        "for p in image_paths:\n",
        "    print('  -', p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb08c0f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Optionally resize images to a consistent input size for HoVerNet\n",
        "# Config\n",
        "TARGET_SIZE = (256, 256)   # choose 256 or 512 etc.\n",
        "RESIZED_DIR = OUT_DIR / \"resized_inputs\"\n",
        "RESIZED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def resize_to_dir(src_paths, dst_dir, size=(256,256)):\n",
        "    dst_paths = []\n",
        "    shape_map = {}  # original (H,W) and resized (H,W), by dst path\n",
        "    for p in tqdm(src_paths, desc=\"Resizing\"):\n",
        "        p = Path(p)\n",
        "        dst = dst_dir / p.name  # flat copy (customize if you want subfolders)\n",
        "        if not dst.exists():\n",
        "            im = Image.open(p).convert(\"RGB\")\n",
        "            W0, H0 = im.size\n",
        "            im = im.resize(size, Image.BILINEAR)\n",
        "            im.save(dst)\n",
        "            shape_map[str(dst)] = {\"orig_hw\": (H0, W0), \"resized_hw\": (size[1], size[0])}\n",
        "        else:\n",
        "            # still record original dims\n",
        "            im = Image.open(p).convert(\"RGB\")\n",
        "            W0, H0 = im.size\n",
        "            shape_map[str(dst)] = {\"orig_hw\": (H0, W0), \"resized_hw\": (size[1], size[0])}\n",
        "        dst_paths.append(str(dst))\n",
        "    return dst_paths, shape_map\n",
        "\n",
        "image_paths_resized, size_info = resize_to_dir(image_paths, RESIZED_DIR, size=TARGET_SIZE)\n",
        "print(f\"Prepared {len(image_paths_resized)} resized images in {RESIZED_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dcc16de",
      "metadata": {},
      "source": [
        "## Run a tool to produce instance outputs (.dat)\n",
        "Here we use `HoverNetTool` as an example. The output files follow a standard schema, with one Python dict per image (serialized via `joblib`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d49bf3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "hovernet = HoverNetTool(\n",
        "    name='hovernet',\n",
        "    model='hovernet_fast-pannuke',\n",
        "    device=DEVICE,\n",
        "    batch_size=4,\n",
        "    num_loader_workers=2,\n",
        "    num_postproc_workers=2,\n",
        ")\n",
        "\n",
        "results = hovernet.process(image_paths=image_paths_resized, save_dir=str(TOOL_OUT_DIR))\n",
        "print('Tool results (first 2):')\n",
        "for r in results[:2]:\n",
        "    print(r)\n",
        "print(f\"Saved {len(results)} .dat files to {TOOL_OUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb88ac15",
      "metadata": {},
      "source": [
        "## Rasterize the tool outputs into feature maps\n",
        "We convert instance outputs (boxes, centroids, contours, types) into pixel‑wise maps. The `HoverNetRasterizer` stacks channels in a stable order (`type[...]` first, then `box`, `centroid`, `contour`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5275a05d",
      "metadata": {},
      "outputs": [],
      "source": [
        "rasterizer = HoverNetRasterizer(\n",
        "    name='hovernet_features',\n",
        "    num_types=6,\n",
        "    include_box=True,\n",
        "    include_centroid=True,\n",
        "    include_contour=True,\n",
        "    include_types=True,\n",
        "    type_mode='points',   # 'points' or 'gaussian'\n",
        "    contour_mode='filled' # 'filled' or 'edge'\n",
        ")\n",
        "\n",
        "saved_feature_paths = []\n",
        "for r in results:\n",
        "    saved = rasterizer.process_and_save(\n",
        "        tool_output_path=str(Path(r['output_path'])),\n",
        "        save_dir=FEAT_OUT_DIR,\n",
        "        image_path=Path(r['input_path']),  # enables exact (H,W)\n",
        "        save_individual=False,\n",
        "    )\n",
        "    saved_feature_paths.append(saved['stacked'])\n",
        "\n",
        "print('Example stacked feature file:', saved_feature_paths[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cbe298d",
      "metadata": {},
      "source": [
        "## Inspect shapes and visualize a few channels (optional)\n",
        "We load one of the saved `[C, H, W]` tensors and display a couple of channels. This is just a sanity check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6428144d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import binary_dilation\n",
        "from skimage import measure\n",
        "\n",
        "def overlay_from_pt(\n",
        "    pt_path,\n",
        "    image_path,\n",
        "    num_types=6,\n",
        "    type_radius=2,       # dilate type points\n",
        "    centroid_radius=2,   # dilate centroid points\n",
        "    edge_thickness=2,    # dilate contour edges\n",
        "    box_outline=True,    # compute box outlines from mask\n",
        "    contour_outline=True # outline contours instead of filled\n",
        "):\n",
        "    # --- load image + features ---\n",
        "    stk = torch.load(pt_path).float()  # [C,H,W]\n",
        "    C,H,W = stk.shape\n",
        "    print(H, W, stk.shape)\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    if img.size != (W,H):\n",
        "        img = img.resize((W,H), Image.BILINEAR)\n",
        "    img = np.asarray(img)\n",
        "\n",
        "\n",
        "    # --- channel split (HoverNetRasterizer order) ---\n",
        "    idx = 0\n",
        "    type_maps = None\n",
        "    if C >= num_types:\n",
        "        type_maps = stk[idx:idx+num_types].cpu().numpy()  # [T,H,W]\n",
        "        idx += num_types\n",
        "    box_map = stk[idx].cpu().numpy() if idx < C else None; idx += 1 if idx < C else 0\n",
        "    centroid_map = stk[idx].cpu().numpy() if idx < C else None; idx += 1 if idx < C else 0\n",
        "    contour_map = stk[idx].cpu().numpy() if idx < C else None\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7,7))\n",
        "    ax.imshow(img)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    # --- TYPE: show dilated colored dots per class ---\n",
        "    if type_maps is not None:\n",
        "        # small palette (extend if needed)\n",
        "        base_colors = np.array([\n",
        "            [1.00, 0.65, 0.00],  # 0\n",
        "            [1.00, 0.00, 0.00],  # 1\n",
        "            [1.00, 1.00, 0.00],  # 2\n",
        "            [0.00, 1.00, 0.00],  # 3\n",
        "            [0.00, 0.00, 0.00],  # 4\n",
        "            [0.00, 0.00, 1.00],  # 5\n",
        "        ], dtype=np.float32)\n",
        "        if base_colors.shape[0] < num_types:\n",
        "            extra = np.random.default_rng(0).random((num_types - base_colors.shape[0], 3))\n",
        "            base_colors = np.vstack([base_colors, extra])\n",
        "\n",
        "        # build a circular structuring element for dilation\n",
        "        if type_radius > 0:\n",
        "            yy, xx = np.ogrid[-type_radius:type_radius+1, -type_radius:type_radius+1]\n",
        "            se = (xx*xx + yy*yy) <= (type_radius*type_radius)\n",
        "        else:\n",
        "            se = np.ones((1,1), dtype=bool)\n",
        "\n",
        "        for cls_id in range(min(num_types, type_maps.shape[0])):\n",
        "            pts = type_maps[cls_id] > 0.5\n",
        "            if not pts.any():\n",
        "                continue\n",
        "            dots = binary_dilation(pts, structure=se)\n",
        "            layer = np.zeros((H,W,4), dtype=np.float32)\n",
        "            rgb = base_colors[cls_id]\n",
        "            layer[dots] = [rgb[0], rgb[1], rgb[2], 1.0]  # solid dots\n",
        "            ax.imshow(layer)\n",
        "\n",
        "    # --- CONTOUR: edge outline from mask (thickened) ---\n",
        "    if contour_map is not None and contour_outline:\n",
        "        filled = contour_map > 0.5\n",
        "        if filled.any():\n",
        "            # outline via marching squares\n",
        "            for c in measure.find_contours(filled.astype(float), level=0.5):\n",
        "                # dilate by drawing multiple offsets\n",
        "                ax.plot(c[:,1], c[:,0], color=\"white\", linewidth=1.0)\n",
        "                # thicken visually by over-plotting nearby offsets\n",
        "                for off in range(1, edge_thickness):\n",
        "                    ax.plot(c[:,1]+off, c[:,0], color=\"white\", linewidth=1.0, alpha=0.7)\n",
        "                    ax.plot(c[:,1]-off, c[:,0], color=\"white\", linewidth=1.0, alpha=0.7)\n",
        "                    ax.plot(c[:,1], c[:,0]+off, color=\"white\", linewidth=1.0, alpha=0.7)\n",
        "                    ax.plot(c[:,1], c[:,0]-off, color=\"white\", linewidth=1.0, alpha=0.7)\n",
        "\n",
        "    # --- BOX: outline rectangles from mask blobs (connected components) ---\n",
        "    if box_map is not None and box_outline:\n",
        "        bm = box_map > 0.5\n",
        "        if bm.any():\n",
        "            # label components then draw min/max rectangles\n",
        "            lab = measure.label(bm, connectivity=2)\n",
        "            regions = measure.regionprops(lab)\n",
        "            for r in regions:\n",
        "                minr, minc, maxr, maxc = r.bbox  # (row/col)\n",
        "                ax.plot([minc, maxc, maxc, minc, minc],\n",
        "                        [minr, minr, maxr, maxr, minr],\n",
        "                        color=\"cyan\", linewidth=1.5, alpha=0.9)\n",
        "\n",
        "    # --- CENTROIDS: dilated dots ---\n",
        "    if centroid_map is not None:\n",
        "        pts = centroid_map > 0.5\n",
        "        if pts.any():\n",
        "            if centroid_radius > 0:\n",
        "                yy, xx = np.ogrid[-centroid_radius:centroid_radius+1, -centroid_radius:centroid_radius+1]\n",
        "                se = (xx*xx + yy*yy) <= (centroid_radius*centroid_radius)\n",
        "                dots = binary_dilation(pts, structure=se)\n",
        "            else:\n",
        "                dots = pts\n",
        "            layer = np.zeros((H,W,4), dtype=np.float32)\n",
        "            layer[dots] = [1, 1, 1, 1.0]  # white\n",
        "            ax.imshow(layer)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---- find the paired image for this feature file (by stem) ----\n",
        "from pathlib import Path\n",
        "pt_path = saved_feature_paths[0]\n",
        "stem = Path(pt_path).stem.replace(\"_features\",\"\")\n",
        "\n",
        "match = next((r for r in results if Path(r[\"input_path\"]).stem == stem), None)\n",
        "image_path = match[\"input_path\"] if match else Path(IMAGE_DIR) / f\"{stem}.png\"\n",
        "\n",
        "overlay_from_pt(pt_path, image_path, num_types=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a34349",
      "metadata": {},
      "source": [
        "## Tips: swapping tools or adding your own\n",
        "- To use a different tool, subclass `Tool` in `tools.py` and implement `process(...)`.\n",
        "- If your tool writes a custom output format, add a matching `Rasterizer` subclass in `rasterizers.py` implementing:\n",
        "  - `load_tool_output(path)`\n",
        "  - `rasterize(tool_output, H, W, ...) -> Dict[str, Tensor]`\n",
        "  - `stack_features(features) -> Tensor[C,H,W]`\n",
        "  - `get_num_channels()`\n",
        "- You can also re‑use the common rasterization primitives (boxes, centroids, contours, types) for many instance‑style outputs."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "neural-additive-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
